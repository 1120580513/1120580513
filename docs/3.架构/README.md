# 架构

> 架构是为了解决软件复杂度

> 复杂度来源: 高性能/高可用/可扩展/成本/安全/规模

## CAP

> 在一个分面式计算系统中，只能同时满足下列两点

- Consistency 一致性
  - 每次访问都能获得最新数据但可能会收到错误响应
- Availability 可用性
  - 每次访问都能收到非错误响应，但不保证获取到最新数据 
- Partition Tolerance 分区容错性
  - 在任意分区网络故障的情况下系统仍能继续运行

> 网络并不可靠，所以分区容错性是必须的，并在可用性和一致性之间做出聚会

---

- CP 一致性和分区容错性，通常在业务需要原子读写时选择
- AP 可用性和分区容错性，通常在业务允许最终一致性或当外部故障时里根系统继续运行
  
### 一致性模式

> 数据的多个副本如何同步，以便让客户端有一致的显示数据

- 弱一致性，写入后可能看到也可能看不到数据
- 最终一致性，写入后最终能看到数据（通常在数毫秒内），数据被异步复制
- 强一致性，写入后访问立即可见，数据被同步复制

### 可用性模式

- 故障切换
  - 工作到备用切换
    - 工作服务器周期性的通知备用服务器，如果信号中断则切换
  - 双工作切换
    - 多个服务器同时管控流量，单一故障并不影响
  - 缺陷
    - 需要增加额外的硬件
    - 如果新写入的数据在复制之前出现故障，则可能会丢失数据

## 负载均衡器

> 将客户端请求按一定规则分配到多个服务器上，将将结果返回给相应客户端

- 负载均衡器很容易成为瓶颈
- 通常是多节点的，以免发生故障
- 优点
  - 防止请求进入不好的服务器
  - 防止资源过载
  - 帮助消除单点故障
  - SSL终结，解密传入的请求并加密服务器响应，这样不用在每台服务器上安装证书
  - Session留存，将客户端的请求路由到同一实例
  - 帮助水平扩展
    - 服务应该是无状态的
    - Session 要考虑集中存储
    - 缓存和数据库一般也要跟着扩展

## DB

### RDBMS

- 复制
  - 主从复制
    - 主库同时负责读写，并将写入同步到多个从库，从库只负责读，主库故障时系统可以以只读模式运行
    - 缺点
      - 将从库提升为主库需要额外的逻辑
  - 主主复制
    - 两个主库都负责读写，写入操作时互相协调
    - 缺点
      - 需要中间层来决定写入哪一个主库
      - 多主库要么不能保证 ACID，要么因同步而产生延迟
      - 主库越多，如果解决冲突越来越重要
  - 复制的缺点
    - 主库在新数据复制到其他节点前故障，可能会丢失数据
    - 写入重放到从库时，从库可能因写入过多故障而影响读取功能
    - 读取从库越多，需要复制的定入数据越多，复制延迟越大
    - 复制意味着更多的硬件和额外的复杂度
- 联合，将数据库按功能分割
- 分区，在磁盘层面将一张表拆分成多个文件
- 分片/分表，分区的数据库版本实现
  - 缺点
    - 往往需要修改应用的逻辑来实现
    - 分片不合理会导致负载的不均衡
    - 联合多个分片的数据会很复杂
- 非规范化
  - 在多个表冗余数据更酷，以写入性能换读取性能
- 调优，在基准测试和性能分析的前提下进行
  - 字段改进
    - 尽量使用 CHAR，连续的内存块
    - TEXT 存储大块文本，存储时仅存储指针
    - INT 存储较大数字，DECIMAL 存储货币类型
    - VARCHAR(255) 是 8 位数字计算的最大字符数，可最大限度的利用字节
    - 尽可能使用 NOT NULL
  - 索引
    - SELECT/GROUP BY/ORDER BY/JOIN 的列如果有索引会更快
    - 索引会占用更多的内存空间
    - 写入会更慢，需要更新索引
    - 加载大量数据时，考虑禁用索引

### NoSQL

> 键-值数据库、文档型数据库、列型数据库、图数据库的统称，数据是非规范化的，联结通常在应用中完成，一般无法实现真正的 ACID，支持最终一致

#### BASE Basically Available/Soft State/Eventual Consistency

> 通常用来描述 NoSQL 的特性，相比 CAP 强调可用性超过一致性

- 基本可用（Basically Available）
  - 分布式系统在出现故障时，允许损失部分可用性，即保证核心可用
- 软状态（Soft State）
  - 允许系统存在中间状态，而该中间状态不会影响系统整体可用性
- 最终一致性（Eventual Consistency）
  - 经过一段时间后，系统最终会变一致 

### RDBMS 和 NoSQL

- RDBMS
  - 结构化的数据
  - 严格的模式
  - 需要复杂的联结操作
  - 事务
  - 清晰的扩展模式
  - 通过索引进行快速查询
- NoSQL
  - 半结构化的数据
  - 动态或灵活的模式
  - 不需要复杂的联结
  - 存储TP甚至PB级的数据
  - 高数据密集的茜茜公主负载
  - IOPS(Input/Output Per Secound 每秒的读写次数) 高吞吐量
  - 适合 NoSQL 的示例
    - 埋点和日志数据
    - 排行榜或得分数据
    - 临时数据，如购物车
    - 频繁访问的热表
    - 元数据/查找表

## 缓存

> 减少服务器和数据库的负载，常用抹平不均匀的负载和突发流量对数据库的影响

- 客户端缓存
- CDN(内容分发网络)，从靠近用户的位置提供内容，通常提供静态内容
- Web 服务器缓存
- 数据库缓存
- 应用缓存，Memcached/Redis 数据保存在内存中
- 建议缓存的内容
  - 用户会话
  - 完全渲染的 Web 页面
  - 活动流
  - 用户图数据
- 缺点
  - 请求的数据如果不存在缓存中，相当于多查了一次缓存
  - 一个节点故障时，新的节点替代会增加延迟
  - 缓存失效和何时更新是个难题
  - 要保证缓存与数据源的一致性
- 缓存模式
  - 直写模式，在缓存中更新，缓存同步写入存储
    - 缺点
      - 大多数数据可能永远不会被访问
      - 出现bug时可能永远不会更新
  - 回写模式，在缓存中更新，异步定入存储
    - 缺点
      - 可能会丢失数据

## 通迅

- HTTP 客户端与服务器之间编码与传输数据的方法
- TCP 传输控制协议 
  - 保证数据完好
    - 每个数据包的序列号和校验码
    - 确认包和自动重传
  - 对网络吞吐量自动进行最佳评估
- UDP 用户数据报协议 
  - 无连接，只在数据报级别有保证，通常效率更高
  - 低延迟，数据延迟比数据丢失重要，自定义错误校正
- RPC 远程过程调用协议
  - 代码看起来像是调用一个本地方法，通常用于内部通迅的性能问题
  - 缺点
    - 客户端与服务实现捆绑紧密
    - 难以调试
    - 无法很方便的修改
- REST 表述性状态转移
  - 标志资源 无论什么操作都使用同一 URI
  - 表示的改变 使用动作、Headers、Body
  - 可自我描述的错误信息 使用 HTTP 的状态码，不重新定义
  - HATEOAS 服务器应该能通过浏览器访问
  - 关注于暴露数据，减少客户端/服务端的耦合程度，常用于公共 HTTP API 接口设计
  - 缺点
    - 资源不是自然组织或结构复杂时无法很好的适应
    - 默认的几个动作可能没法满足需求
    - 为渲染单个页面，需要多次通信
    - 随着时间推移，接口字段越来越多，老客户端会收到不需要的字段

## 附录

### 2 的次方

```
Power           Exact Value         Approx Value        Bytes
---------------------------------------------------------------
7                             128
8                             256
10                           1024   1 thousand           1 KB
16                         65,536                       64 KB
20                      1,048,576   1 million            1 MB
30                  1,073,741,824   1 billion            1 GB
32                  4,294,967,296                        4 GB
40              1,099,511,627,776   1 trillion           1 TB
```

### 延迟数

```
Latency Comparison Numbers
--------------------------
L1 cache reference                           0.5 ns
Branch mispredict                            5   ns
L2 cache reference                           7   ns                      14x L1 cache
Mutex lock/unlock                           25   ns
Main memory reference                      100   ns                      20x L2 cache, 200x L1 cache
Compress 1K bytes with Zippy            10,000   ns       10 us
Send 1 KB bytes over 1 Gbps network     10,000   ns       10 us
Read 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSD
Read 1 MB sequentially from memory     250,000   ns      250 us
Round trip within same datacenter      500,000   ns      500 us
Read 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memory
Disk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtrip
Read 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSD
Read 1 MB sequentially from disk    30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSD
Send packet CA->Netherlands->CA    150,000,000   ns  150,000 us  150 ms

Notes
-----
1 ns = 10^-9 seconds
1 us = 10^-6 seconds = 1,000 ns
1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns
```
